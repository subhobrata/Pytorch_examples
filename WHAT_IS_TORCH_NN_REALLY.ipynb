{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WHAT IS TORCH.NN REALLY.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhobrata/Pytorch_examples/blob/master/WHAT_IS_TORCH_NN_REALLY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "eFMGeturGI5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "URL = \"http://deeplearning.net/data/mnist/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHjh7RBS9KVi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Nz-RAsx9LlA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AgP9p_KzHTcf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import gzip\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVRE2lOnHcYH",
        "colab_type": "code",
        "outputId": "1b9a4c4e-8175-4459-edb5-a535e4210ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8H/LFmKD6IYI7AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "H7A40f8RHwRw",
        "colab_type": "code",
        "outputId": "9cd3c1e4-be08-41f8-c249-7061775457ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x_train, y_train, x_valid, y_valid = map(\n",
        "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
        ")\n",
        "n, c = x_train.shape\n",
        "x_train, x_train.shape, y_train.min(), y_train.max()\n",
        "print(x_train, y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.min(), y_train.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n",
            "torch.Size([50000, 784])\n",
            "tensor(0) tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zKCmyVg1Kfaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "with torch.no_grad() is a context manager and is used to prevent calculating gradients in the following code block.\n",
        "Usually it is used when you evaluate your model and don’t need to call backward() to calculate the gradients and update the corresponding parameters.\n",
        "Also, you can use it to initialize the weights with torch.nn.init functions, since you don’t need the gradients there either.\n",
        "\n",
        "requires_grad on the other hand is used when creating a tensor, which should require gradients. Usually you don’t need this in the beginning, as all parameters which require gradients are already wrapped in nn.Modules in the nn package.\n",
        "You could set this property e.g. on your input tensor, if you need to update your input for example in an adversarial training setup."
      ]
    },
    {
      "metadata": {
        "id": "ljTtksvHJMcq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "weights = torch.randn(784, 10) / math.sqrt(784)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(10, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h9sG28PwKvPA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_softmax(x):\n",
        "  return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "  return log_softmax(xb@weights+bias)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GzHqtjl1P66-",
        "colab_type": "code",
        "outputId": "035cd6cd-b084-48b9-e8fe-4817c9577424",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "bs=64 #batch_size\n",
        "\n",
        "xb = x_train[0:bs] # a mini batch size from x\n",
        "preds = model(xb) #prediction\n",
        "preds[0], preds.shape\n",
        "print(preds[0],preds.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-2.1557, -2.7084, -1.8120, -2.3411, -2.5744, -2.2799, -2.2937, -2.4389,\n",
            "        -2.0959, -2.6828], grad_fn=<SelectBackward>) torch.Size([64, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RSXcWAqIQ9bC",
        "colab_type": "code",
        "outputId": "59d896f4-4421-420d-fcec-739e008db190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "def nll(input,target):\n",
        "  return -input[range(target.shape[0]),target].mean()\n",
        "\n",
        "loss_func = nll\n",
        "type(nll)\n",
        "type(loss_func)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "function"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "8VTAm561R43-",
        "colab_type": "code",
        "outputId": "30c508cd-d19e-4b6e-fc1b-e3b23436a9ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "yb = y_train[0:bs]\n",
        "print(loss_func(preds,yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3222, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lIj2nr4LJ1LB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(out,yb):\n",
        "  preds = torch.argmax(out,dim=1)\n",
        "  return (preds == yb).float().mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRIdFeWIjz_x",
        "colab_type": "code",
        "outputId": "a602566e-5c7d-4008-f30c-06f543c28bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(accuracy(preds,yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1406)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WdQeAittoJGf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "lr = 0.5  # learning rate\n",
        "epochs = 2  # how many epochs to train for\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        #         set_trace()\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fdXxrdpqtvzZ",
        "colab_type": "code",
        "outputId": "9d01b58c-8d8e-467e-f7cb-26f211dfd176",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0825, grad_fn=<NegBackward>) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kDapb2-rw2Dx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "loss_func = F.cross_entropy\n",
        "\n",
        "def model(xb):\n",
        "  return xb@weights + bias\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TnQZgtxRx2WP",
        "colab_type": "code",
        "outputId": "9781c7a2-54b4-44a3-f008-b790d1a6a332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0825, grad_fn=<NllLossBackward>) tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K2CBJ7juyEAf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class Mnist_Logistic(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(784,10)/math.sqrt(784))\n",
        "    self.bias = nn.Parameter(torch.zeros(10))\n",
        "    \n",
        "  def forward(self,xb):\n",
        "    return xb@self.weights+self.bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-IFfiE00JDX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Mnist_Logistic()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4_uKvU91fmU",
        "colab_type": "code",
        "outputId": "b462a63a-9534-4cc4-8ec7-59fc222365e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3344, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Hp6ElZD26Os",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    weights -= weights.grad * lr\n",
        "    bias -= bias.grad * lr\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7iJaoCKL30FW",
        "colab_type": "code",
        "outputId": "8ca2c94e-bfcf-4ffb-b294-e47f74bb3ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ade642173198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "7GBnnnWw9M5B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4a27beb1-0516-4e08-e152-6231fe99a1a3"
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for p in model.parameters(): p -= p.grad * lr\n",
        "    model.zero_grad()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ade642173198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "z_pKqUGxBnrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QNELK1TSBzNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "88bc12a0-7102-4a99-c7b1-2e994f250639"
      },
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    model = Mnist_Logistic()\n",
        "    return model, optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "model, opt = get_model()\n",
        "print(loss_func(model(xb), yb))\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        start_i = i * bs\n",
        "        end_i = start_i + bs\n",
        "        xb = x_train[start_i:end_i]\n",
        "        yb = y_train[start_i:end_i]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3835, grad_fn=<NllLossBackward>)\n",
            "tensor(0.0816, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-f5s3-nG-Xgj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "opt.step()\n",
        "opt.zero_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g0k88bvxKs1X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmpqOLgqK6s5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVhwaLapK2Lv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xb = x_train[start_i:end_i]\n",
        "yb = y_train[start_i:end_i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tY22ST8jLYd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "xb,yb = train_ds[i*bs:i*bs+bs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HPo1Ck2Lmyi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ba97ace-74d7-485b-8370-43e8b0e3619c"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i in range((n - 1) // bs + 1):\n",
        "        xb, yb = train_ds[i * bs: i * bs + bs]\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0842, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5kiCtg4SMl3x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUYJnAs_OHRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7fYTAhdCOkHJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range((n-1)//bs + 1):\n",
        "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
        "    pred = model(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L5UACWc0Q5Ky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for xb,yb in train_dl:\n",
        "    pred = model(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kweokv2DQ-N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a47c014-29e6-4620-ec85-cf79b905cee2"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for xb, yb in train_dl:\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "print(loss_func(model(xb), yb))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0813, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4eWtuDXgSNHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hjzqOgxhSShg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valid_ds = TensorDataset(x_valid, y_valid)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pF3pMP6FTKfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "40782b75-f287-41ea-d5c8-8fa5aecf183c"
      },
      "cell_type": "code",
      "source": [
        "model, opt = get_model()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "        pred = model(xb)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)\n",
        "\n",
        "    print(epoch, valid_loss / len(valid_dl))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 tensor(0.3183)\n",
            "1 tensor(0.3197)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vO6Ji4eLWI6K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAUb_ENEWsYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "        print(epoch, val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUQzkT00YcKZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs * 2),\n",
        "    )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIsl7IS9YgzY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5189e6c3-3253-4d1c-9862-1c3819496e13"
      },
      "cell_type": "code",
      "source": [
        "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
        "model, opt = get_model()\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.3032454061985016\n",
            "1 0.3027892698764801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7RQO3UW5YuNL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,16,kernal_size=3,stride=2,padding=1)\n",
        "    self.conv2 = nn.Conv2d(16,16,kernal_size=3,stride=2,padding=1)\n",
        "    self.conv3 = nn.Conv2d(16,10,kernal_size=3,stride=2,padding=1)\n",
        "    \n",
        "  def forward(self,xb):\n",
        "    xb = xb.view(-1,1,28,28)\n",
        "    xb = F.relu(self.conv1(xb))\n",
        "    xb = F.relu(self.conv2(xb))\n",
        "    xb = F.relu(self.conv2(xb))\n",
        "    xb = F.avg_pool2d(xb,4)\n",
        "    return xb.view(-1,xb.size(1))\n",
        "  \n",
        "lr = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKkUcqBBeJgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "56248802-2856-4e05-feef-98e6bdd3057d"
      },
      "cell_type": "code",
      "source": [
        "model = Mnist_CNN()\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-5ea83f4943ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMnist_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-1e3005ea62b5>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernal_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernal_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernal_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'kernal_size'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0sxHPF9izY7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "\n",
        "def preprocess(x):\n",
        "    return x.view(-1, 1, 28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PDSEb4hRz7SD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f8c16677-fe59-4b49-857d-4f9e27473a4b"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    Lambda(preprocess),\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AvgPool2d(4),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "\n",
        "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.43244185638427735\n",
            "1 0.23764800176620485\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}